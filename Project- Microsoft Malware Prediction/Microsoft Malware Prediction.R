# load in packages
library(MASS)
library(dplyr)
library(tidyr)
library(ggplot2)
library(cowplot)
library(tidyverse)
library(splitstackshape)
library(glmnet)
install.packages("bigmemory")
library(bigmemory)
install.packages("biglasso")
library(biglasso)
library(ncvreg)
library(lars)
install.packages("caret")
library(caret)

#load the data an check its type
train<-read.csv('C:\\Users\\jingy\\OneDrive\\Documents\\6015\\w4\\final project\\train.csv')
str(train)
#convert factor to charactor
train %>% mutate_if(is.factor, as.character) -> train_1 #convert factor to charactor
str(train_1)#check the type again

#fill NAs with specific value
train_1$IsProtected[is.na(train_1$IsProtected)]<-2
unique(train_1$IsProtected)
train_1$PuaMode[which(train_1$PuaMode=='')] <- 'out' 
unique(train_1$PuaMode)

#fill the blanks with NA
for(i in ncol(train_1)){
  c1 = length(which(train_1[,i]==''))
  if(c1>0){
    train_1[,i][train_1[,i]==""] <- "NA"
  }
}

#split the data into 'machine' and 'census'
machine<-train_1[,-c(35:80)]
census<-train_1[,35:80]

#NA check
col = c()#the column with NAs
rat = c()# NA% of this column
for(i in 1:ncol(machine)){
  c2 = sum(is.na(machine[,i]))
  if(c2>0){
    col<-c(col,i)
    rat<-c(rat,c2/nrow(machine))}
}
na_info <- data.frame(col,rat)
na_info #9th,16th,

#delete columns
colnames(train_1)[9]#DefaultBrowsersIdentifier
colnames(train_1)[16]#OrganizationIdentifier
drop_col1<-c('DefaultBrowsersIdentifier','OrganizationIdentifier')
drop_col2<-c('RtpStateBitfield','IsSxsPassiveMode','AVProductsInstalled','AVProductsEnabled','IeVerIdentifier','Wdft_RegionIdentifier')
drop_col<-c(drop_col1,drop_col2)
machine[,drop_col]<-NULL

#delete rows with NAs
machine_1<-machine[complete.cases(machine), ]
dim(machine_1)# 7684852 29
sum(is.na(machine_1))# 0

#select 60k row data
machine_2<-machine_1[1:60000,]
dim(machine_2)# 60000 29

#Firewall
sum(is.na(machine_2$Firewall)) #0

#smartscreen
machine_2$SmartScreen[which(machine_2$SmartScreen=='')]<-'ExistNotSet'

#export machine_2 to csv
write.csv(machine_2,"C:\\Users\\jingy\\OneDrive\\Documents\\6015\\final project\\60k.csv")

# load in the cleansed dataset
df<-read.csv(file.choose(),header = T)
str(df)
df <- select(df,-c(MachineIdentifier, IsBeta))
d_freq <- aggregate(df$EngineVersion, 
                    by=list(OCC_TITLE=ocp$OCC_TITLE), FUN=sum)

# fill in the NaN with -1 for numerical variables
# check the type of the variables
lapply(df, typeof)
for (i in colnames(df)){Numeric <- df[is.numeric(i)==T]}
for(i in ncol(Numeric)){
  c1 = length(which(Numeric[,i]==''))
  if(c1>0){
    Numeric[,i][Numeric[,i]==""] <- -1
  }
}

# fill in the NaN with the most frequent one for binary variables
is.binary <- function(v) {
  x <- unique(v)
  length(x) - sum(is.na(x)) == 2L
}
for (i in colnames(df)){Binary <- df[is.binary(i)==T]}
for(i in ncol(Binary)){
  c1 = length(which(Binary[,i]==''))
  if(c1>0){
    Binary[,i][Binary[,i]==""] <- mode(i)
  }
}

# group the EngineVersion
table(df$EngineVersion)
# delete those with 0.1% contribution
df$EngineVersion <- as.character(df$EngineVersion)
df <- df[!table(df$EngineVersion)[df$EngineVersion] < 10,]
df$EngineVersion <- as.factor(df$EngineVersion)
unique(df$EngineVersion)

# group the Appversion
table(df$AppVersion)
df <- cSplit(df, "AppVersion", ".")
df <- select(df,-c(AppVersion_3, AppVersion_4))
df <- unite(df, "AppVersion", AppVersion_1, AppVersion_2, sep=".")

# group the Avsigversion
table(df$AvSigVersion)
df$AvSigVersion <- read.fwf(textConnection(as.character(df$AvSigVersion)), 5)

# group the productstateidentifier
length(unique(df$AVProductStatesIdentifier)) # 1406
# delete the column AVProductStatesIdentifier
df <- select(df,-AVProductStatesIdentifier)

# frequency table for categorical variable
table(df$SkuEdition)
table(df$IsProtected)
table(df$AutoSampleOptIn)
table(df$PuaMode)
table(df$SMode)
table(df$SmartScreen)
table(df$Firewall)
table(df$UacLuaenable)
table(df$Wdft_IsGamer)

# spelling check
df$SkuEdition[df$SkuEdition=="Enterprise LTSB"] <- "Enterprise"
unique(df$SkuEdition)
df$SmartScreen[df$SmartScreen=="ExistsNotSet"] <- "ExistNotSet"
df$SmartScreen[df$SmartScreen=="off"] <- "Off"
df$SmartScreen[df$SmartScreen=="on"] <- "On"
unique(df$SmartScreen)

# delete the too skewed columns
# The goal is to eliminate features that account for more than 99% of all eigenvalues
df <- select(df,-c(AutoSampleOptIn, PuaMode, SMode))

# check the impact of column UacLuaenable on detection
UacLuaenable <- subset(df, df$UacLuaenable==0)
table(UacLuaenable$HasDetections)
UacLuaenable_2 <- subset(df, df$UacLuaenable==1)
table(UacLuaenable_2$HasDetections)

# delete the column UacLuaenable
df <- select(df,-c(UacLuaenable))

# delete the unnesscary collumn OSbuild because it is the summary of the other columns
df <- select(df,-c(OsBuildLab))

#Group the OSPlatformSubRelease
table(df$OsVer)
#Turning the unsubtaintial ones into the same group
df$OsVer[df$OsVer=="10.0.1.44"] <- "10.0.0.0"
df$OsVer[df$OsVer=="10.0.3.0"] <- "10.0.0.0"
df$OsVer[df$OsVer=="6.1.0.0"] <- "6.3.0.0"
df$OsVer[df$OsVer=="6.1.1.0"] <- "6.3.0.0"
df$OsVer[df$OsVer=="6.3.1.0"] <- "6.3.0.0"
df <- df[!table(df$OsVer)[df$OsVer] < 1,]
unique(df$OsVer)

# group the OSbuild
table(df$OsBuild)

# delete those with 0.1% contribution
df <- df[!table(df$OsBuild)[as.character(df$OsBuild)] < 20,]

# group OsPlatformSubRelease
table(train$OsPlatformSubRelease)

# group the OsSuite
table(df$OsSuite)
# delete those with 784 
df <- df[!table(df$OsSuite)[as.character(df$OsSuite)] < 2,]
unique(df$OsSuite)

write.csv(df,"C:\\Users\\CharlotteC\\Desktop\\cleansed.csv")
# load in the new cleansed data
df <- read.csv(file.choose(),header = T)

# logistic regression model
str(df)
df <- select(df,-X)
logistic <- glm(HasDetections~., data=df, family = "binomial")
summary(logistic)
confint(logistic)

# R^2
ll.null <- logistic$null.deviance/-2
ll.proposed <- logistic$deviance/-2
(ll.null-ll.proposed)/ll.null # R^2 = 0.02799
1-pchisq(2*(ll.proposed-ll.null), df=(length(logistic$coefficients)-1)) # p-value = 0

# create a new data.frame that contains the probabilities
predicted.df <- data.frame(
  probability.of.HasDetections=logistic$fitted.values, 
  HasDetections=df$HasDetections)

# sort the data.frame from low probabilities to high probabilities
predicted.df <- predicted.df[
  order(predicted.df$probability.of.HasDetections,decreasing = FALSE),]

# rank each sample
predicted.df$rank <- 1:nrow(predicted.df)

# draw the data
ggplot(data=predicted.df, aes(x=rank, y=probability.of.HasDetections))+
  geom_point(aes(color=HasDetections),alpha=1,shape=4,stroke=2)+xlab("Index")+
  ylab("Predicted probability of having detections")

# lasso regression model
y <- df$HasDetections
x <- model.matrix(HasDetections~., df)
lasso_fit <- glmnet(x, y, family = "binomial",alpha = 1, lambda = NULL)
plot(lasso_fit, xvar = "lambda", label=5)
cv_fit <- cv.glmnet(x,y,family = "binomial", alpha=1, nlambda=1000)
plot(cv_fit, label = T)
cv_fit$lambda.min # 0.0026
cv_min <- glmnet(x,y, alpha = 1,family = "binomial", lambda = cv_fit$lambda.min)
cv_min$beta

cv_fit$lambda.1se # 0.0057
cv_1se <- glmnet(x,y, alpha = 1,family = "binomial",lambda = cv_fit$lambda.1se)
cv_1se$beta

# r2 <- 1 - cv_fit$cvm/var(y)
# plot(cv_fit$lambda,r2)
# max(r2) 

# confusion matrix for logistic
cutoff <- .5
testdata <- df[1:18000,]
x.data.test <- model.matrix(HasDetections~., testdata)
p <- predict(logistic, newx = x.data.test, type = "response")
table(y, p > 0.5)

# confusion matrix for lasso
glmnet1 <- glmnet(x, y, alpha=1, family = "binomial")
pred <- predict(glmnet1, newx = x.data.test, type = "response")
pred1 <- data.frame(rowMeans(pred, na.rm = FALSE, dims = 1))
pred.factor <- as.factor(ifelse(pred1>cutoff,1,0))
my_data2 <- factor(data.frame(data = testdata$HasDetections, type = "real")[,1])
f.conf <- confusionMatrix(pred.factor,my_data2)
print(f.conf)

#INPUT THE DATASET 
df.rf <- df[, -c(5:8)]   #eliminate the all the geography indicators

# TURNING THE DEPEDNENT VARIABLES INTO FACTORS 
# df.rf[0:18] = as.factor(unlist(df.rf[0:18]))   
# ENCODING THE TARGET FREATURE AS FACTOR
df.rf$ProductName = factor(df.rf$ProductName)
df.rf$EngineVersion = factor(df.rf$EngineVersion)
df.rf$AvSigVersion = factor(df.rf$AvSigVersion)
df.rf$HasTpm = factor(df.rf$HasTpm)
df.rf$Platform = factor(df.rf$Platform)
df.rf$Processor = factor(df.rf$Processor)
df.rf$OsBuild = factor(df.rf$OsBuild)
df.rf$OsVer = factor(df.rf$OsVer)
df.rf$OsSuite = factor(df.rf$OsSuite)
df.rf$OsPlatformSubRelease = factor(df.rf$OsPlatformSubRelease)
df.rf$IsProtected= factor(df.rf$IsProtected)
df.rf$SmartScreen = factor(df.rf$SmartScreen)
df.rf$Firewall = factor(df.rf$Firewall)
df.rf$Wdft_IsGamer = factor(df.rf$Wdft_IsGamer)
df.rf$AppVersion = factor(df.rf$AppVersion)
df.rf

# sPLITTING THE DATASET INTO 6 DIFFERENT GROUPS OF TREES
install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(df.rf, SplitRatio = 0.33) #spliting the data into 3 subsets
split_a = subset(df.rf, split == TRUE) 
split2 = subset(df.rf, split == FALSE)
split = sample.split(split2, SplitRatio = 0.5)
split_b = subset(split2, split == TRUE) 
split_c = subset(split2, split == FALSE)
split = sample.split(split_a, SplitRatio = 0.50) #spliting the data into 6 subsets
tree_1 = subset(split_a, split == TRUE)
tree_2 = subset(split_a, split == FALSE)
split = sample.split(split_b, SplitRatio = 0.50)
tree_3 = subset(split_b, split == TRUE)
tree_4 = subset(split_b, split == FALSE)
split = sample.split(split_c, SplitRatio = 0.50) 
tree_5 = subset(split_c, split == TRUE)
tree_6 = subset(split_c, split == FALSE)

split_1 = sample.split(tree_1, SplitRatio = 0.75) #Assigning test and train set of tree 1 
train_set_1 = subset(tree_1, split == TRUE)
test_set_1 = subset(tree_1, split == FALSE)
split_2 = sample.split(tree_2, SplitRatio = 0.75) #Assigning test and train set of tree 2  
train_set_2 = subset(tree_2, split == TRUE)
test_set_2 = subset(tree_2, split == FALSE)
split_3 = sample.split(tree_3, SplitRatio = 0.75) #Assigning test and train set of tree 3  
train_set_3 = subset(tree_3, split == TRUE)
test_set_3 = subset(tree_3, split == FALSE)
split_4 = sample.split(tree_3, SplitRatio = 0.75) #Assigning test and train set of tree 4  
train_set_4 = subset(tree_3, split == TRUE)
test_set_4 = subset(tree_3, split == FALSE)
split_5 = sample.split(tree_5, SplitRatio = 0.75) #Assigning test and train set of tree 5  
train_set_5 = subset(tree_5, split == TRUE)
test_set_5 = subset(tree_5, split == FALSE)
split_6 = sample.split(tree_6, SplitRatio = 0.75) #Assigning test and train set of tree 6  
train_set_6 = subset(tree_6, split == TRUE)
test_set_6 = subset(tree_6, split == FALSE)

# FITTING RANDOM FOREST CLASSIFICATION TO THE TRAINING SET
#install.packages('randomForest')
install.packages("randomForest")
library(randomForest)
set.seed(123)
classifier1 = randomForest(x = train_set_1[,-17],
                           y = train_set_1$HasDetections,
                           ntree = 500)
classifier2 = randomForest(x = train_set_2[,-17],
                           y = train_set_2$HasDetections,
                           ntree = 500)
classifier3 = randomForest(x = train_set_3[,-17],
                           y = train_set_3$HasDetections,
                           ntree = 500)
classifier4 = randomForest(x = train_set_4[,-17],
                           y = train_set_4$HasDetections,
                           ntree = 500)
classifier5 = randomForest(x = train_set_5[,-17],
                           y = train_set_5$HasDetections,
                           ntree = 500)
classifier6 = randomForest(x = train_set_6[,-17],
                           y = train_set_6$HasDetections,
                           ntree = 500)
#x has to be the dataframe,matrix  
#y is the vector 

# PREDICTING THE TEST RESULT
y1_pred = predict(classifier1, newdata = test_set_1[,-17])
y2_pred = predict(classifier2, newdata = test_set_2[,-17])
y3_pred = predict(classifier3, newdata = test_set_3[,-17])
y4_pred = predict(classifier4, newdata = test_set_4[,-17])
y5_pred = predict(classifier5, newdata = test_set_5[,-17])
y6_pred = predict(classifier6, newdata = test_set_6[,-17])

#GETTING THE PREDICTION TO BE IN THE BINARY FORMAT
y1_pred <-floor(0.5+ y1_pred)
y2_pred <-floor(0.5+ y2_pred)
y3_pred <-floor(0.5+ y3_pred)
y4_pred <-floor(0.5+ y4_pred)
y5_pred <-floor(0.5+ y5_pred)
y6_pred <-floor(0.5+ y6_pred)

# MAKING THE CONFUSION MATRIX
cm1 = table(test_set_1[, 17], y1_pred)
cm2 = table(test_set_2[, 17], y2_pred)
cm3 = table(test_set_3[, 17], y3_pred)
cm4 = table(test_set_4[, 17], y4_pred)
cm5 = table(test_set_5[, 17], y5_pred)
cm6 = table(test_set_6[, 17], y6_pred)

cm1
cm2
cm3
cm4
cm5
cm6

#TRYING TO OPTIMIZE THE MODEL
y1_pred_1  <-floor(0.48+ y1_pred)
cm1_1 = table(test_set_1[, 17], y1_pred_1)
cm1_1
y1_pred_2  <-floor(0.49+ y1_pred)
cm1_2 = table(test_set_1[, 17], y1_pred_2)
cm1_2
y1_pred_3  <-floor(0.51+ y1_pred)
cm1_3 = table(test_set_1[, 17], y1_pred_3)
cm1_3

# GBM based on the 60k
df[,'CityIdentifier']<-NULL

# convert to factor
for (i in 1:ncol(df)) {
  if(class(df[,i])!='Factor'){
    df[,i]<-as.factor(df[,i])
  }
}

#seperate into train and test data
set.seed(329)
train_index<-sample(1:nrow(df),42000)
train_set<-df[train_index,]
test_set<-df[-train_index,]
y_train<-train_set[,'HasDetections']
x_train<-train_set[,c(1:18,20)]
y_test<-test_set[,'HasDetections']
x_test<-test_set[,c(1:18,20)]

install.packages('xgboost')
library(xgboost)

x_train <- data.matrix(x_train)
y_train <- data.matrix(y_train)
x_test <- data.matrix(x_test)

fit <- xgboost(data = x_train, label =  y_train, nrounds = 1000,
              objective = "binary:logistic",max_depth = 6, 
              eta = 1,eval_metric ="auc")

xgb.prob1 <- predict(fit,x_test)
xgb.pred <- ifelse(xgb.prob1>0.5,1,0)
table(y_test,xgb.pred)
importance <- xgb.importance(colnames(df[,c(1:18,20)]),model = fit)
importance<-data.frame(importance)
write.csv(importance,'C:\\Users\\jingy\\OneDrive\\Documents\\6015\\fea_im.csv')

# GBM based on the 100k
df.100k <- read.csv(file.choose(),header = T)
df.100k[,'X']<-NULL
# convert to numeric
num_data <- c('Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_PrimaryDiskTotalCapacity','Census_ProcessorCoreCount',
            'Census_SystemVolumeTotalCapacity','Census_TotalPhysicalRAM')
df.100k[num_data] <- lapply(df.100k[num_data], as.numeric)
# convert to factor
for (i in 1:ncol(df.100k)) {
  if(class(df.100k[,i])=='integer'){
    df.100k[,i]<-as.factor(df.100k[,i])
  }
}
df.100k['CityIdentifier']<-NULL
df.100k['AVProductStatesIdentifier']<-NULL
df.100k['AvSigVersion']<-NULL
dim(df.100k)

set.seed(330)
train_index<-sample(1:nrow(df.100k),70000)
train_set<-df.100k[train_index,]
test_set<-df.100k[-train_index,]
y_train<-train_set[,'HasDetections']
x_train<-train_set[,c(1:50)]
y_test<-test_set[,'HasDetections']
x_test<-test_set[,c(1:50)]

x_train <- data.matrix(x_train)
y_train <- data.matrix(y_train)
x_test <- data.matrix(x_test)

fit <- xgboost(data = x_train, label =  y_train, nrounds = 1000,
              objective = "binary:logistic",max_depth = 6, 
              eta = 1,eval_metric ="auc")
xgb.prob1 = predict(fit,x_test)
xgb.pred = ifelse(xgb.prob1>0.5,1,0)
table(y_test, xgb.pred)

importance<-xgb.importance(colnames(df.100k[,c(1:50)]),model = fit)
importance<-data.frame(importance)
write.csv(importance,'C:\\Users\\jingy\\OneDrive\\Documents\\6015\\fea_im100k.csv')


